{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOELxjzr5C9h5tifImTePzx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maushamkumar/Cats_vs_dogs_image_classification/blob/main/dog_vs_cat_image_classification_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bs9SbiMW2-Pi"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ./kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FDlqTsZ3eZT",
        "outputId": "71906fda-2658-4c6c-ccb6-099be6580159"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "dogs-vs-cats.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/dogs-vs-cats.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjMPHS1G3eb1",
        "outputId": "1f2f8f27-faf1-4d48-a436-9642a74a627c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dogs-vs-cats.zip\n",
            "replace /content/dogs_vs_cats/test/cats/cat.10.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from keras.utils import plot_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GRIovI3i3ehD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_cats = ['/content/dogs_vs_cats/train/cats/cat.0.jpg', '/content/dogs_vs_cats/train/cats/cat.1.jpg']"
      ],
      "metadata": {
        "id": "wGat76733ejp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/dogs_vs_cats/train/dogs')"
      ],
      "metadata": {
        "id": "fCgTRcGA3emQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.sample(os.listdir('/content/dogs_vs_cats/train/dogs'), 5)"
      ],
      "metadata": {
        "id": "Cr1jOW353eo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /content/dogs_vs_cats/train/cats/cat.0.jpg"
      ],
      "metadata": {
        "id": "A3lRgGqI3er_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.join(\"/content/dogs_vs_cats/train/cats/\", 'cat.0.jpg')"
      ],
      "metadata": {
        "id": "GNsn6yXo3eu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images_from_directory(directory_path, class_animal, num_images=9):\n",
        "    # Retrieve list of all file names in the directory\n",
        "    image_filenames = os.listdir(directory_path)\n",
        "\n",
        "    # If there are fewer images than requested, we'll just show them all\n",
        "    if len(image_filenames) < num_images:\n",
        "        print(f\"Only found {len(image_filenames)} images in {directory_path}, displaying them all.\")\n",
        "        num_images = len(image_filenames)\n",
        "\n",
        "    # Randomly select 'num_images' number of file names\n",
        "    selected_images = random.sample(image_filenames, num_images)\n",
        "\n",
        "    # Plotting the images\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(8, 8))  # Adjust the size as needed\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i, image_file in enumerate(selected_images):\n",
        "        image_path = os.path.join(directory_path, image_file)\n",
        "        image = Image.open(image_path)\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(f\"Image: {class_animal}\")\n",
        "        axes[i].axis('off')  # Hide the axis\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ic0PDDYn3exf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Placeholder for the directory path\n",
        "cat_directory_path = '/content/dogs_vs_cats/train/cats'  # Replace with your directory path\n",
        "plot_images_from_directory(cat_directory_path, class_animal = 'Cat')"
      ],
      "metadata": {
        "id": "EuQr2H8-3e0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Placeholder for the directory path\n",
        "dog_directory_path = '/content/dogs_vs_cats/train/dogs'  # Replace with your directory path\n",
        "plot_images_from_directory(dog_directory_path, class_animal = 'Dog')"
      ],
      "metadata": {
        "id": "-MUAuU3j3e3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_images = os.listdir(cat_directory_path)\n",
        "dog_images = os.listdir(dog_directory_path)\n",
        "\n",
        "classes_animals = ['Cats', 'Dogs']\n",
        "count = [len(cat_images), len(dog_images)]\n",
        "\n",
        "print(count)"
      ],
      "metadata": {
        "id": "VSy4fNxX3e6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating both a bar chart and a pie chart side by side in a single figure\n",
        "\n",
        "# Setting up a figure and axes for two subplots: one for the bar chart, one for the pie chart\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
        "\n",
        "# Bar chart on the first subplot\n",
        "ax[0].bar(classes_animals, count, color=['blue', 'green'])\n",
        "ax[0].set_xlabel('Animal Class')\n",
        "ax[0].set_ylabel('Image Count')\n",
        "ax[0].set_title('Count of Cat and Dog Images')\n",
        "\n",
        "# Pie chart on the second subplot\n",
        "colors = ['#ff9999','#66b3ff']\n",
        "ax[1].pie(count, labels=classes_animals, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "ax[1].set_title('Distribution of Cat and Dog Images')\n",
        "ax[1].axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "\n",
        "# Adjust the layout so that both subplots fit nicely\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6t5vtGo33e9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import imghdr\n",
        "\n",
        "# Define the list of acceptable image extensions\n",
        "image_exts = ['jpeg', 'jpg', 'png']\n",
        "\n",
        "# Path to the directory containing image classes and possibly other nested subdirectories\n",
        "data_dir = '/content/dogs_vs_cats'\n",
        "\n",
        "# Walk through all directories and files in the dataset\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    for file in files:\n",
        "        # Construct the path to the current file\n",
        "        file_path = os.path.join(root, file)\n",
        "\n",
        "        try:\n",
        "            # Check the file type of the current file\n",
        "            file_type = imghdr.what(file_path)\n",
        "\n",
        "            # If the file extension is not in the allowed list, remove it\n",
        "            if file_type not in image_exts:\n",
        "                print(f'Image not in ext list {file_path}')\n",
        "                os.remove(file_path)\n",
        "            else:\n",
        "                # Proceed to process the image if needed, for example, reading it with OpenCV\n",
        "                img = cv2.imread(file_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Print out the issue and the path of the problematic file\n",
        "            print(f'Issue with file {file_path}. Error: {e}')\n",
        "            # Optionally, remove files that cause exceptions\n",
        "            os.remove(file_path)"
      ],
      "metadata": {
        "id": "qp3VF3JK3fAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def image_to_array(image_path):\n",
        "    \"\"\"\n",
        "    Read an image and convert it to a numpy array.\n",
        "\n",
        "    Parameters:\n",
        "    image_path (str): The path to the image file.\n",
        "\n",
        "    Returns:\n",
        "    np.array: The image as a numpy array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with Image.open(image_path) as img:\n",
        "            image_array = np.array(img)\n",
        "            return image_array\n",
        "    except IOError:\n",
        "        print(f\"Could not read the image file at {image_path}.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "Oiw8yRV93fD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_to_array('/content/dogs_vs_cats/train/dogs/dog.1000.jpg')"
      ],
      "metadata": {
        "id": "lSP83n7a4Vmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = '/content/dogs_vs_cats/train/dogs/dog.1000.jpg'\n",
        "\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread(image)\n",
        "\n",
        "# If the image is loaded successfully, print its pixel values\n",
        "if img is not None:\n",
        "    print(img)\n",
        "    print(img.shape)\n",
        "else:\n",
        "    print(\"The image could not be loaded. Please check the path and file permissions.\")"
      ],
      "metadata": {
        "id": "H7N1MoCr4XhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Load the image with PIL and convert to a NumPy array\n",
        "img_pil = Image.open(image)\n",
        "img_array = np.array(img_pil)\n",
        "\n",
        "# Print the NumPy array of the image\n",
        "print(img_array)\n",
        "\n",
        "# Print the NumPy array of the image\n",
        "print(img_array.shape)"
      ],
      "metadata": {
        "id": "xs-gWnp94ZJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set path to the dataset\n",
        "base_dir = '/content/dogs_vs_cats/train'\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
      ],
      "metadata": {
        "id": "yyzgDMnV4azK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Using 20% of data for validation\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),  # Resizing images to 150x150\n",
        "    batch_size=20,\n",
        "    class_mode='binary',  # Since we use binary_crossentropy loss, we need binary labels\n",
        "    subset='training')  # Set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary',\n",
        "    subset='validation')  # Set as validation data"
      ],
      "metadata": {
        "id": "GkoWGLL_4ebL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Class Labels"
      ],
      "metadata": {
        "id": "MBlfZ1FH4jo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing class labels for the training data\n",
        "train_class_labels = train_generator.class_indices\n",
        "print(\"Training class labels:\", train_class_labels)"
      ],
      "metadata": {
        "id": "UbvwRMLi4fyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have define 0 for cats and 1 for dogs"
      ],
      "metadata": {
        "id": "RS_Ln91v4ywW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing class labels for the validation data\n",
        "validation_class_labels = validation_generator.class_indices\n",
        "print(\"Validation class labels:\", validation_class_labels)"
      ],
      "metadata": {
        "id": "lF9VP2fW4wbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualising the Batch Images"
      ],
      "metadata": {
        "id": "cHaHTjUW5IW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(train_generator)\n",
        "images, labels\n"
      ],
      "metadata": {
        "id": "BNSqAzK95HWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot the images and their labels\n",
        "def plot_images_from_generator(generator, num_images = 4):\n",
        "  # Get a batch of images and labels from the generator\n",
        "  images, labels = next(generator)\n",
        "\n",
        "  # Set up the plot\n",
        "  fig, axes = plt.subplots(1, num_images, figsize=(20, 20))\n",
        "  axes = axes.flatten()\n",
        "\n",
        "  for img, label, ax in zip(images, labels, axes):\n",
        "    # Images preprocessing might differ, adjust accordingly\n",
        "    ax.imshow(img)\n",
        "    # Set the title to the label\n",
        "    # Inverse the class indices dictionary to get class names from labels\n",
        "    class_labels = dict((v, k) for k, v in generator.class_indices.items())\n",
        "    ax.set_title(class_labels[int(label)])\n",
        "    ax.axis('off')\n",
        "  plt.tight_layout\n",
        "  plt.show()\n",
        "\n",
        "# Now, call this function with your training generator\n",
        "plot_images_from_generator(train_generator)"
      ],
      "metadata": {
        "id": "kjYQKDSl5RHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.reset()"
      ],
      "metadata": {
        "id": "_iQOrP866cKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic CNN Model"
      ],
      "metadata": {
        "id": "sQ-B-__36tDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid') # Sigmoid activation for binary classification\n",
        "\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "GGShZbop6r_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='Architecture.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "vGK76rs_79Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter Calculation in CNN Layers\n",
        "\n",
        "### Conv2D Layer\n",
        "\n",
        "The formula to calculate the number of parameters in a Conv2D layer is:\n",
        "\n",
        "Parameters = (kernel_height ✖︎ kernel_width ✖︎ input_channels + 1) x number_The \"+1\" accounts for the bias term for each filter.\n",
        "\n",
        "\n",
        "### 1. First Conv2D Layer\n",
        "* input shape: (150, 150, 3)\n",
        "* Number of Filters: 32\n",
        "* Filter size: (3, 3)\n",
        "* Parameters:\n",
        "\n",
        "      * (3 ✖︎ 3 ✖︎ 3 + 1) x 32 = 896\n",
        "\n",
        "\n",
        "### 2. Second Conv2D Layer\n",
        "* Input channels: 32 (from the previous Conv2D layer)\n",
        "* Number of Filters: 64\n",
        "* Filter size: (3, 3)\n",
        "* Parameters:\n",
        "\n",
        "      * (3 ✖︎ 3 ✖︎ 32 + 1) x 64 = 18496\n",
        "\n",
        "\n",
        "### 3. Third Conv2D Layer\n",
        "* Input channels: 64\n",
        "* Number of Filters: 128\n",
        "* Filter size: (3, 3)\n",
        "* Parameters:\n",
        "\n",
        "      * (3 ✖︎ 3 ✖︎ 64 + 1) x 128 = 73856\n",
        "\n",
        "\n",
        "### 3. Fourth Conv2D Layer\n",
        "* Input channels: 128\n",
        "* Number of Filters: 128\n",
        "* Filter size: (3, 3)\n",
        "* Parameters:\n",
        "\n",
        "      * (3 ✖︎ 3 ✖︎ 128 + 1) x 128 = 147584\n",
        "\n",
        "\n",
        "## MaxPooling Layer\n",
        "MaxPooling layers do not have parameters. They only reduce the size of the input they're applied to, based on their pool size and stride.\n",
        "\n",
        "## Flatten Layer\n",
        "The Flatten layer itself doesn't have parameters.It simply reshape the input but does not affect the total parameter count.\n",
        "\n",
        "## Dense Layer\n",
        "The Formula for a Dense (fully connected) layer is:\n",
        "\n",
        "           *parameters = (input_size + 1) x output_size\n",
        "\n",
        "## 1. First Dense Layer\n",
        "\n",
        "* Assuming Flatten output size: X (you'll need to calculate this based on the output of the last pooling layer).\n",
        "* Output size: 512\n",
        "* parameters: (X + 1) x 512 = 262,016\n",
        "\n",
        "## 2. Second Dense Layer\n",
        "\n",
        "* Input size: 512\n",
        "* Output size: 1(for binary classification)\n",
        "* Parameters:\n",
        "\n",
        "      * (512 + 1) x 1 = 513\n",
        "\n"
      ],
      "metadata": {
        "id": "nO94IrS88RFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "x326bUuF8Kaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 20\n",
        "train_steps = np.ceil(train_generator.samples/batch)\n",
        "validation_steps_per_epoch = np.ceil(validation_generator.samples/batch)\n",
        "print(train_steps, validation_steps_per_epoch)"
      ],
      "metadata": {
        "id": "tYdUrrsXBVnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_steps,\n",
        "    epochs = 10,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = 200\n",
        ")"
      ],
      "metadata": {
        "id": "DERBAlzUBrmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "id": "dvnkTuLUB5Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "iYHfmtm8GMyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3inTnRuoGdQf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}